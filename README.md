Key Context:

User wants to implement Retrieval-Augmented Generation (RAG) and structured prompting techniques with limited resources and free-tier AI models.
User is working with free versions of AI models (ChatGPT, Claude) that have:
Small context windows
No file upload capability
No persistent memory across sessions
User's hardware setup:
Chromebook with limited internal Linux storage
Mount and leverage external storage
User is handling large files (2+ million tokens)
Primary Objective
To create a system that allows the user to effectively review and reason over large prompts, code, and text files despite the limitations of free-tier AI models, by leveraging RAG and structured prompting techniques (MCP, ACP, A2A).



Summary:

The user is seeking to build a workflow that allows them to:
Store files, code fragments, and instructions on their external USB drive
Strategically access and feed this information to limited AI models
Use advanced prompting techniques to maintain context and guide the AI through complex reasoning tasks
Effectively manage large projects that exceed normal context limitations of free models
The challenge is designing an efficient system that works within these technical constraints while still enabling comprehensive code review and analysis capabilities.
