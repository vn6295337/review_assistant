{
  "content": "     \n    def tokenize(self, text):\n        \"\"\"Convert text to lowercase and split into tokens\"\"\"\n        # Remove special characters and convert to lowercase\n        text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n        # Split into tokens and filter out stop words\n        tokens = [word for word in text.split() if word not in self.stop_words and len(word) > 1]\n        return tokens\n    \n    def get_term_frequency(self, text):\n        \"\"\"Calculate term frequency for a text\"\"\"\n        tokens = self.tokenize(text)\n        term_freq = {}\n        \n        # Count term frequencies\n        for token in tokens:\n            if token in term_freq:\n                term_freq[token] += 1\n            else:\n                term_freq[token] = 1\n        \n        # Add new terms to vocabulary and update document frequencies\n        for token in set(tokens):\n            self.vocabulary.add(token)\n            if token in self.term_doc_freq:\n                self.term_doc_freq[token] += 1\n            else:\n                self.term_doc_freq[token] = 1\n        \n        return term_freq\n    \n    def fit(self, texts):\n        \"\"\"Process a list of texts to build vocabulary and IDF values\"\"\"\n        self.document_count = len(texts)\n        \n        for text in texts:\n            self.get_term_frequency(text)\n    \n    def get_vector(self, text):\n        \"\"\"Convert text to TF-IDF vector\"\"\"\n        term_freq = self.get_term_frequency(text)\n        vector = {}\n        \n        # Calculate TF-IDF for each term\n        for term, freq in term_freq.items():\n            # Term frequency component\n            tf = freq / max(len(self.tokenize(text)), 1)\n            \n            # Inverse document frequency component (avoid division by zero)\n            idf = math.log((self.document_count + 1) / (self.term_doc_freq.get(term, 0) + 1)) + 1\n            \n            # TF-IDF score\n            vector[term] = tf * idf\n        \n        return vector\n    \n    def similarity(self, vec1, vec2):\n        \"\"\"Calcul",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_140836.txt",
    "chunk_id": "050ac12f9b7f_37",
    "start_char": 66600,
    "end_char": 68600,
    "created_at": "2025-05-21T08:41:32+00:00"
  }
}