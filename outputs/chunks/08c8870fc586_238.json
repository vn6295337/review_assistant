{
  "content": ", convert_to_tensor=True)\n    similarity_scores = util.cos_sim(query_vector, [c[\"embedding\"] for c in embedded_chunks])[0]\n    top_indices = similarity_scores.argsort(descending=True)[:top_k]\n    return [(embedded_chunks[i], float(similarity_scores[i])) for i in top_indices]\n\ndef start_interactive_session(chunks, model):\n    \"\"\"Run a command-line interface for querying the chunk index.\"\"\"\n    print(\"\\nğŸ§  Ask your question (type 'exit' or 'quit' to end):\")\n    while True:\n        user_input = input(\"\\n> \")\n        if user_input.lower() in {\"exit\", \"quit\"}:\n            print(\"ğŸ‘‹ Session ended.\")\n            break\n        results = perform_similarity_search(user_input, chunks, model)\n        print(\"\\nğŸ“š Top Results:\")\n        for idx, (result, score) in enumerate(results, start=1):\n            snippet = result[\"text\"][:500] + (\"...\" if len(result[\"text\"]) > 500 else \"\")\n            print(f\"\\n#{idx} ({result['file']}, Score: {score:.2f})\\n{snippet}\")\n\ndef main(chunks_directory):\n    print(f\"\\nğŸ“¦ Loading data from: {chunks_directory}\")\n    chunks = load_chunks_from_directory(chunks_directory)\n    if not chunks:\n        print(\"âŒ No chunks found in the directory!\")\n        return\n\n    print(f\"âœ… {len(chunks)} chunks loaded.\")\n    print(\"ğŸ“¡ Initializing embedding model...\")\n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n    print(\"ğŸ” Generating embeddings for chunks...\")\n    embedded_chunks = compute_embeddings(chunks, model)\n    \n    start_interactive_session(embedded_chunks, model)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"RAG Assistant: Ask questions about your codebase\")\n    parser.add_argument(\"--chunks-dir\", type=str, required=True, help=\"Directory containing JSON chunk files\")\n    args = parser.parse_args()\n    main(args.chunks_dir)\n\n\nDO we need both the files? regardless of your answer, also perform refactoring, if required.\nChatGPT said:\nDo you need both assistants?\nFile\tFootprint\tStrengths\tWhen to use\nsimple_rag_assistant.py\tPure",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_125041.txt",
    "chunk_id": "08c8870fc586_238",
    "start_char": 428400,
    "end_char": 430400,
    "created_at": "2025-05-21T07:21:41+00:00"
  }
}