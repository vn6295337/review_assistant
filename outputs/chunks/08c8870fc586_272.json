{
  "content": " Path(chunks_dir)\n    \n    # Filter by extensions if specified\n    if extensions:\n        ext_list = extensions.split(',')\n        # Make sure each extension starts with a dot\n        ext_list = [ext if ext.startswith('.') else f'.{ext}' for ext in ext_list]\n    else:\n        ext_list = None\n    \n    # Walk through the chunks directory\n    for root, _, files in os.walk(chunks_dir):\n        for file in files:\n            # Skip non-JSON files\n            if not file.endswith('.json'):\n                continue\n            \n            # Skip files that don't match the specified extensions\n            if ext_list:\n                file_path = Path(file)\n                original_ext = file_path.stem.split('.')[-1]  # Assuming chunks are named like \"file.py.chunk.json\"\n                if f'.{original_ext}' not in ext_list:\n                    continue\n            \n            # Load the chunk\n            try:\n                with open(Path(root) / file, 'r', encoding='utf-8') as f:\n                    chunk_data = json.load(f)\n                    chunks.append(chunk_data)\n            except Exception as e:\n                print(f\"Error loading chunk file {file}: {e}\", file=sys.stderr)\n    \n    return chunks\n\ndef search_chunks(chunks, query, limit=10):\n    \"\"\"Search for the query in the chunks.\"\"\"\n    # Split the query into keywords\n    keywords = query.lower().split()\n    \n    # Define a scoring function for chunks\n    def score_chunk(chunk):\n        content = chunk.get('content', '').lower()\n        \n        # Count occurrences of each keyword\n        scores = [content.count(keyword) for keyword in keywords]\n        \n        # If any keyword is not found, return 0\n        if 0 in scores:\n            return 0\n        \n        # Return the sum of occurrences\n        return sum(scores)\n    \n    # Score all chunks\n    scored_chunks = [(chunk, score_chunk(chunk)) for chunk in chunks]\n    \n    # Filter out chunks with zero score\n    scored_chunks = [(chunk, score) for chunk, s",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_125041.txt",
    "chunk_id": "08c8870fc586_272",
    "start_char": 489600,
    "end_char": 491600,
    "created_at": "2025-05-21T07:21:41+00:00"
  }
}