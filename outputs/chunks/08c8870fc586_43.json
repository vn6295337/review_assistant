{
  "content": ".\"\"\"\n    texts = [chunk[\"text\"] for chunk in chunks]\n    embeddings = embedding_model.encode(texts, convert_to_tensor=True)\n    for chunk, embedding in zip(chunks, embeddings):\n        chunk[\"embedding\"] = embedding\n    return chunks\n\ndef perform_similarity_search(query, embedded_chunks, embedding_model, top_k=5):\n    \"\"\"Search the top_k most relevant chunks given a user query.\"\"\"\n    query_vector = embedding_model.encode(query, convert_to_tensor=True)\n    similarity_scores = util.cos_sim(query_vector, [c[\"embedding\"] for c in embedded_chunks])[0]\n    top_indices = similarity_scores.argsort(descending=True)[:top_k]\n    return [(embedded_chunks[i], float(similarity_scores[i])) for i in top_indices]\n\ndef start_interactive_session(chunks, model):\n    \"\"\"Run a command-line interface for querying the chunk index.\"\"\"\n    print(\"\\n🧠 Ask your question (type 'exit' or 'quit' to end):\")\n    while True:\n        user_input = input(\"\\n> \")\n        if user_input.lower() in {\"exit\", \"quit\"}:\n            print(\"👋 Session ended.\")\n            break\n        results = perform_similarity_search(user_input, chunks, model)\n        print(\"\\n📚 Top Results:\")\n        for idx, (result, score) in enumerate(results, start=1):\n            snippet = result[\"text\"][:500] + (\"...\" if len(result[\"text\"]) > 500 else \"\")\n            print(f\"\\n#{idx} ({result['file']}, Score: {score:.2f})\\n{snippet}\")\n\ndef main(chunks_directory):\n    print(f\"\\n📦 Loading data from: {chunks_directory}\")\n    chunks = load_chunks_from_directory(chunks_directory)\n    if not chunks:\n        print(\"❌ No chunks found in the directory!\")\n        return\n\n    print(f\"✅ {len(chunks)} chunks loaded.\")\n    print(\"📡 Initializing embedding model...\")\n    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\n    print(\"🔍 Generating embeddings for chunks...\")\n    embedded_chunks = compute_embeddings(chunks, model)\n    \n    start_interactive_session(embedded_chunks, model)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(desc",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_125041.txt",
    "chunk_id": "08c8870fc586_43",
    "start_char": 77400,
    "end_char": 79400,
    "created_at": "2025-05-21T07:21:40+00:00"
  }
}