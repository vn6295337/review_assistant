{
  "content": "lower().split()\n    \n    # Define a scoring function for chunks\n    def score_chunk(chunk):\n        content = chunk.get('content', '').lower()\n        \n        # Count occurrences of each keyword\n        scores = [content.count(keyword) for keyword in keywords]\n        \n        # If any keyword is not found, return 0\n        if 0 in scores:\n            return 0\n        \n        # Return the sum of occurrences\n        return sum(scores)\n    \n    # Score all chunks\n    scored_chunks = [(chunk, score_chunk(chunk)) for chunk in chunks]\n    \n    # Filter out chunks with zero score\n    scored_chunks = [(chunk, score) for chunk, score in scored_chunks if score > 0]\n    \n    # Sort by score in descending order\n    scored_chunks.sort(key=lambda x: x[1], reverse=True)\n    \n    # Return the top N chunks\n    return [chunk for chunk, _ in scored_chunks[:limit]]\n\ndef highlight_matches(content, query, context=0):\n    \"\"\"Highlight matches in the content.\"\"\"\n    keywords = query.lower().split()\n    lines = content.split('\\n')\n    result = []\n    \n    # Track which lines to include\n    include_lines = set()\n    \n    # Find lines containing keywords\n    for i, line in enumerate(lines):\n        if any(keyword in line.lower() for keyword in keywords):\n            # Add the line and context lines\n            for j in range(max(0, i - context), min(len(lines), i + context + 1)):\n                include_lines.add(j)\n    \n    # Create the highlighted content\n    for i, line in enumerate(lines):\n        if i in include_lines:\n            # Highlight the keywords\n            highlighted_line = line\n            for keyword in keywords:\n                pattern = re.compile(f'({re.escape(keyword)})', re.IGNORECASE)\n                highlighted_line = pattern.sub(r'**\\1**', highlighted_line)\n            \n            result.append(highlighted_line)\n    \n    return '\\n'.join(result)\n\ndef search_command_handler(args):\n    \"\"\"Handle the search command.\"\"\"\n    # Load chunks\n    print(f\"Loading chunks f",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_125041.txt",
    "chunk_id": "08c8870fc586_78",
    "start_char": 140400,
    "end_char": 142400,
    "created_at": "2025-05-21T07:21:40+00:00"
  }
}