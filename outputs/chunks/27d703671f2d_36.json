{
  "content": "ummarizer.py accordingly) to avoid re‑summarising unchanged chunks.\nClipboard/editor\tFalls back to user’s $EDITOR if defined.\nComments / headings\tClean section dividers for easier reading.\nSave, make it executable:\n\nchmod +x review_assistant/scripts/full_rag_workflow.sh\n…and you’re ready to go. Ping me if you’d like tweaks or if any helper scripts still need refactoring!\n\nYou said:\nThere are two files under review_assistant/python:\n1. simple_rag_assistant.py:\n#!/usr/bin/env python3\n\nimport os\nimport glob\nimport json\nimport argparse\nimport sys\nimport math\nimport re\nfrom pathlib import Path\nfrom datetime import datetime\nimport readline  # For better command line input handling\n\nclass SimpleVectorizer:\n    \"\"\"A simple text vectorizer that doesn't require external libraries\"\"\"\n    \n    def __init__(self):\n        # Common English stop words to ignore\n        self.stop_words = {\n            'a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'what',\n            'when', 'where', 'how', 'which', 'who', 'whom', 'this', 'that', 'these',\n            'those', 'then', 'just', 'so', 'than', 'such', 'both', 'through',\n            'about', 'for', 'is', 'of', 'while', 'during', 'to', 'from', 'in',\n            'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then',\n            'once', 'here', 'there', 'all', 'any', 'both', 'each', 'few', 'more',\n            'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n            'same', 'so', 'than', 'too', 'very', 'can', 'will', 'just', 'should',\n            'now', 'with', 'by', 'be', 'been', 'being', 'am', 'are', 'was', 'were'\n        }\n        \n        # Dictionary to store term frequencies across all documents\n        self.document_count = 0\n        self.term_doc_freq = {}\n        self.vocabulary = set()\n        \n    def tokenize(self, text):\n        \"\"\"Convert text to lowercase and split into tokens\"\"\"\n        # Remove special characters and convert to lowercase\n        text = re.sub(r'[^\\w\\s]', ' ', te",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_113849.txt",
    "chunk_id": "27d703671f2d_36",
    "start_char": 64800,
    "end_char": 66800,
    "created_at": "2025-05-21T06:08:50+00:00"
  }
}