{
  "content": "_rag_assistant.py --chunks-dir /path/to/chunks\n\"\"\"\n\nimport argparse, glob, json, math, os, re, sys\nfrom datetime import datetime\nfrom pathlib import Path\n\n# ───────────────────────────────────────────────────────────\n# 1. Pull CHUNKS_DIR from config.sh if we’re inside repo\n# ───────────────────────────────────────────────────────────\nCONFIG_PATH = Path(__file__).resolve().parents[1] / \"scripts\" / \"config.sh\"\nif CONFIG_PATH.is_file():\n    # crude parse of \"export VAR=value\"\n    with open(CONFIG_PATH) as cf:\n        for line in cf:\n            if line.startswith(\"export CHUNKS_DIR\"):\n                CHUNKS_DIR_DEFAULT = line.split(\"=\", 1)[1].strip().strip('\"')\n                break\nelse:\n    CHUNKS_DIR_DEFAULT = \"./outputs/chunks\"\n\n# ───────────────────────────────────────────────────────────\n# 2. Tiny TF‑IDF implementation\n# ───────────────────────────────────────────────────────────\nclass SimpleVectorizer:\n    stop_words = {\n        'a','an','the','and','or','but','if','because','as','what','when','where','how',\n        'which','who','whom','this','that','these','those','again','about','for','is',\n        'of','while','during','to','from','in','out','on','off','over','under','through',\n        'no','not','only','own','same','so','than','too','very','can','will','just','now',\n        'with','by','be','been','being','am','are','was','were'\n    }\n\n    def __init__(self):\n        self.doc_cnt, self.df, self.vocab = 0, {}, set()\n\n    def _tokenise(self, txt:str):\n        txt = re.sub(r'[^\\w\\s]', ' ', txt.lower())\n        return [w for w in txt.split() if w not in self.stop_words and len(w) > 1]\n\n    def _tf(self, tokens):\n        tf = {}\n        for t in tokens: tf[t] = tf.get(t, 0) + 1\n        return tf\n\n    def fit(self, docs):\n        self.doc_cnt = len(docs)\n        for doc in docs:\n            toks = set(self._tokenise(doc))\n            for tok in toks:\n                self.vocab.add(tok)\n                self.df[tok] = self.df.get(tok, 0) + 1\n\n    def vector(self, d",
  "metadata": {
    "source": "/mnt/chromeos/removable/USB Drive/review_assistant/codebase/chat_sessions/Chat_with_CFO_20250521_113849.txt",
    "chunk_id": "27d703671f2d_45",
    "start_char": 81000,
    "end_char": 83000,
    "created_at": "2025-05-21T06:08:50+00:00"
  }
}